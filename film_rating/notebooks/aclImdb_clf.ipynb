{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c8f8b1a-0ce9-45a8-bf4f-bf64dbad42d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ktc/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "import transformers\n",
    "from transformers import BertTokenizer, AutoConfig, AutoModel, modeling_outputs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torcheval.metrics import R2Score\n",
    "import pickle\n",
    "\n",
    "DATA_DIR = \"../datasets\"\n",
    "MODEL_DIR = \"../models\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732b7729-118f-4654-9804-dfab4385b092",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3aa88c7-b269-4c28-9077-8e6af254c9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR)\n",
    "\n",
    "!rm -rf ./checkpoints\n",
    "\n",
    "source = os.path.join(DATA_DIR, \"aclImdb_v1.tar.gz\")\n",
    "if not os.path.exists(source):\n",
    "    !torify wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz -P $DATA_DIR\n",
    "\n",
    "!tar -xf $source -C /tmp\n",
    "train_dir = \"/tmp/aclImdb/train\"\n",
    "test_dir = \"/tmp/aclImdb/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ad8e751-8f3d-485e-8f8b-0ef8ffbfefae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(path):\n",
    "    review = []\n",
    "    for label in [\"pos\", \"neg\"]:\n",
    "        files = os.listdir(os.path.join(path, label))\n",
    "        for file in files:\n",
    "            with open(os.path.join(path, label, file)) as f:\n",
    "                text = f.readline()\n",
    "                rating = file.split(\".\")[0].split(\"_\")[1]\n",
    "                review.append([text, label, int(rating)])\n",
    "    df = pd.DataFrame(review, columns=[\"text\", \"label\", \"rating\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75787cc8-4458-4342-9f6d-72a291f3dacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 3),\n",
       " (25000, 3),\n",
       " label\n",
       " pos    12500\n",
       " neg    12500\n",
       " Name: count, dtype: int64,\n",
       " label\n",
       " pos    12500\n",
       " neg    12500\n",
       " Name: count, dtype: int64,\n",
       " rating\n",
       " 1     5100\n",
       " 10    4732\n",
       " 8     3009\n",
       " 4     2696\n",
       " 7     2496\n",
       " 3     2420\n",
       " 2     2284\n",
       " 9     2263\n",
       " Name: count, dtype: int64,\n",
       " rating\n",
       " 1     5022\n",
       " 10    4999\n",
       " 8     2850\n",
       " 4     2635\n",
       " 3     2541\n",
       " 9     2344\n",
       " 7     2307\n",
       " 2     2302\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = extract_data(train_dir)\n",
    "test_df = extract_data(test_dir)\n",
    "train_df.shape, test_df.shape, \\\n",
    "train_df.label.value_counts(), test_df.label.value_counts(), \\\n",
    "train_df.rating.value_counts(), test_df.rating.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5573ae6-68ea-4f26-b94d-15f50e662eb1",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f809c682-b1dd-48cd-9a64-8a8a4a28701d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13b42331-5963-4780-8383-e596024e98a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8082"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer=\"char_wb\", ngram_range = (1,3))\n",
    "X_train = vectorizer.fit_transform(train_df[\"text\"])\n",
    "X_test = vectorizer.transform(test_df[\"text\"])\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(train_df[\"label\"])\n",
    "y_test = le.transform(test_df[\"label\"])\n",
    "clf = LogisticRegression(max_iter = 10_000).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3db75a8a-595c-4c13-8fbb-17a2050424b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(MODEL_DIR, \"vectorizer.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "with open(os.path.join(MODEL_DIR, \"label_encoder.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(le, f)\n",
    "with open(os.path.join(MODEL_DIR, \"clf.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50659784-6261-4863-9c32-ac9ce10b8840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdabbece-3ed6-4e95-b40e-db31ef0d15ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.202815\n",
      "0:\tlearn: 0.0812353\ttest: 0.0784610\tbest: 0.0784610 (0)\ttotal: 483ms\tremaining: 1m 36s\n",
      "10:\tlearn: 0.3364505\ttest: 0.3143412\tbest: 0.3143412 (10)\ttotal: 5.61s\tremaining: 1m 36s\n",
      "20:\tlearn: 0.4204975\ttest: 0.3793310\tbest: 0.3793310 (20)\ttotal: 10.7s\tremaining: 1m 31s\n",
      "30:\tlearn: 0.4660014\ttest: 0.4137897\tbest: 0.4137897 (30)\ttotal: 15.9s\tremaining: 1m 26s\n",
      "40:\tlearn: 0.4983486\ttest: 0.4343162\tbest: 0.4343162 (40)\ttotal: 21s\tremaining: 1m 21s\n",
      "50:\tlearn: 0.5264498\ttest: 0.4490742\tbest: 0.4490742 (50)\ttotal: 26.1s\tremaining: 1m 16s\n",
      "60:\tlearn: 0.5553902\ttest: 0.4619172\tbest: 0.4619172 (60)\ttotal: 31.5s\tremaining: 1m 11s\n",
      "70:\tlearn: 0.5803161\ttest: 0.4747657\tbest: 0.4747657 (70)\ttotal: 36.6s\tremaining: 1m 6s\n",
      "80:\tlearn: 0.6017811\ttest: 0.4785598\tbest: 0.4785598 (80)\ttotal: 41.6s\tremaining: 1m 1s\n",
      "90:\tlearn: 0.6193026\ttest: 0.4832783\tbest: 0.4832783 (90)\ttotal: 46.6s\tremaining: 55.8s\n",
      "100:\tlearn: 0.6370172\ttest: 0.4851170\tbest: 0.4851170 (100)\ttotal: 52.2s\tremaining: 51.1s\n",
      "110:\tlearn: 0.6517772\ttest: 0.4893193\tbest: 0.4893193 (110)\ttotal: 57.2s\tremaining: 45.9s\n",
      "120:\tlearn: 0.6644559\ttest: 0.4920327\tbest: 0.4920327 (120)\ttotal: 1m 2s\tremaining: 40.6s\n",
      "130:\tlearn: 0.6766226\ttest: 0.4944326\tbest: 0.4944326 (130)\ttotal: 1m 7s\tremaining: 35.4s\n",
      "140:\tlearn: 0.6874323\ttest: 0.4973103\tbest: 0.4973103 (140)\ttotal: 1m 12s\tremaining: 30.2s\n",
      "150:\tlearn: 0.6984803\ttest: 0.4991954\tbest: 0.4991954 (150)\ttotal: 1m 17s\tremaining: 25s\n",
      "160:\tlearn: 0.7088243\ttest: 0.5011021\tbest: 0.5011021 (160)\ttotal: 1m 22s\tremaining: 19.9s\n",
      "170:\tlearn: 0.7190069\ttest: 0.5018610\tbest: 0.5018610 (170)\ttotal: 1m 26s\tremaining: 14.8s\n",
      "180:\tlearn: 0.7279219\ttest: 0.5028420\tbest: 0.5028420 (180)\ttotal: 1m 31s\tremaining: 9.65s\n",
      "190:\tlearn: 0.7366692\ttest: 0.5040854\tbest: 0.5040854 (190)\ttotal: 1m 36s\tremaining: 4.57s\n",
      "199:\tlearn: 0.7441483\ttest: 0.5049698\tbest: 0.5049698 (199)\ttotal: 1m 41s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5049698445\n",
      "bestIteration = 199\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x76a4cf85ead0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42\n",
    ")\n",
    "catboost = CatBoostRegressor(iterations=200, eval_metric='R2', metric_period=10)\n",
    "catboost.fit(X_train, y_train, eval_set=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef776e41-1993-4cee-b62d-8c12c1bc8b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5221826991653495"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, catboost.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fea786d-f85a-4ce8-8ba4-6cd6dee047dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(MODEL_DIR, \"reg.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(catboost, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e832b9d9-51db-4b04-b873-f786c3451f7b",
   "metadata": {},
   "source": [
    "## Передобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "369ae515-3c92-4189-9975-64608af897de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImdbDataset():\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def _lemmatizer(self, doc):\n",
    "        doc = \" \".join(str(doc).split())\n",
    "        doc = [token.lemma_ for token in nlp(doc) if token.lemma_ not in stop_words]\n",
    "        return \" \".join(doc)\n",
    "\n",
    "    def _lemmatize(self, text):\n",
    "        tqdm.pandas()\n",
    "        text = text.progress_apply(self._lemmatizer)\n",
    "        return text\n",
    "\n",
    "    def _label_encoder(self, labels):\n",
    "        return [1 if label == \"pos\" else 0 for label in labels]\n",
    "\n",
    "    def _preprocess_function(self, batch, tokenizer, max_length):\n",
    "        return tokenizer(batch['text'], truncation=True, max_length=max_length)\n",
    "\n",
    "    def from_df(self, data):\n",
    "        data = Dataset.from_dict({\n",
    "            \"text\": self._lemmatize(data[\"text\"]), \n",
    "            \"labels\": self._label_encoder(data[\"label\"]),\n",
    "            \"rating\": data[\"rating\"]}\n",
    "        )\n",
    "        tokenized_data = data.map(\n",
    "            self._preprocess_function, \n",
    "            batched=True, \n",
    "            fn_kwargs={\"tokenizer\": tokenizer, \"max_length\": 512}\n",
    "        )\n",
    "        tokenized_data = tokenized_data.class_encode_column(\"labels\")\n",
    "        return tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88649771-edd6-43bd-a4ad-719efdf59cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(checkpoint, clean_up_tokenization_spaces=True)\n",
    "data_collator = transformers.DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "dataset = ImdbDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "02127aaf-edab-4af1-9bf3-0a1b37a985e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c57ceca3594965b645c6b25d53512d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15af0f4304aa4fd49189c5ef816f9347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f64cad8ce0c64ac9b163377a5081476c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stringifying the column:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45b1e0aae594ae7939b586cc64500be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7101186485524e849f1adf4a388aa4db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds = dataset.from_df(train_df)\n",
    "train_ds.save_to_disk(os.path.join(DATA_DIR, \"train.hf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146bd068-34b7-41c6-9cc4-676afe165f0e",
   "metadata": {},
   "source": [
    "## Архитектура"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93cb5111-da71-43fd-85b7-08c3997aa00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hid_dim=1024):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_channels, hid_dim),\n",
    "            nn.LayerNorm(hid_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hid_dim, hid_dim),\n",
    "            nn.LayerNorm(hid_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hid_dim, out_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "class ImdbBertClassifier(nn.Module):\n",
    "    def __init__(self, out_features):\n",
    "        super(ImdbBertClassifier, self).__init__()\n",
    "        self.out_features = out_features\n",
    "        self.config = AutoConfig.from_pretrained(checkpoint, output_attentions=True, attn_implementation=\"eager\")\n",
    "        self.backbone = AutoModel.from_pretrained(checkpoint, config=self.config)\n",
    "        in_features = self.backbone.pooler.dense.out_features\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = Classifier(in_features, out_features)\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None):\n",
    "        out = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        out = self.dropout(out.pooler_output)\n",
    "        logits = self.classifier(out)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(logits, labels)\n",
    "        out = modeling_outputs.TokenClassifierOutput({\"loss\": loss, \"logits\": logits})\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18cb8f0-b1b7-453b-9651-c39855ba2ae6",
   "metadata": {},
   "source": [
    "## Модель для предсказания статуса отзыва"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e29499ec-5b7c-43a6-bba5-03fbfd5bb653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4800\n",
      "1    4800\n",
      "Name: count, dtype: int64\n",
      "0    1200\n",
      "1    1200\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9000' max='9000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9000/9000 2:03:53, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.657900</td>\n",
       "      <td>0.457637</td>\n",
       "      <td>0.809583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.522800</td>\n",
       "      <td>0.442038</td>\n",
       "      <td>0.832917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.455500</td>\n",
       "      <td>0.421957</td>\n",
       "      <td>0.819583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.435100</td>\n",
       "      <td>0.379953</td>\n",
       "      <td>0.830833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.402200</td>\n",
       "      <td>0.410502</td>\n",
       "      <td>0.836250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.392900</td>\n",
       "      <td>0.367281</td>\n",
       "      <td>0.851250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.379000</td>\n",
       "      <td>0.369013</td>\n",
       "      <td>0.831667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>0.352784</td>\n",
       "      <td>0.856667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.357900</td>\n",
       "      <td>0.347854</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.347700</td>\n",
       "      <td>0.353267</td>\n",
       "      <td>0.853750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.340600</td>\n",
       "      <td>0.349288</td>\n",
       "      <td>0.852083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.327600</td>\n",
       "      <td>0.344278</td>\n",
       "      <td>0.858750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.334900</td>\n",
       "      <td>0.338489</td>\n",
       "      <td>0.857500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.318300</td>\n",
       "      <td>0.342700</td>\n",
       "      <td>0.857917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.320700</td>\n",
       "      <td>0.335855</td>\n",
       "      <td>0.855833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9000, training_loss=0.3923843824598524, metrics={'train_runtime': 7434.1657, 'train_samples_per_second': 19.37, 'train_steps_per_second': 1.211, 'total_flos': 0.0, 'train_loss': 0.3923843824598524, 'epoch': 15.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = datasets.load_from_disk(os.path.join(DATA_DIR, \"train.hf\"))\n",
    "small_train_ds = train_ds.train_test_split(\n",
    "    train_size=12000, stratify_by_column=\"labels\"\n",
    ")\n",
    "split_ds = small_train_ds[\"train\"].train_test_split(\n",
    "    test_size=0.2, stratify_by_column=\"labels\"\n",
    ")\n",
    "print(pd.Series(split_ds[\"train\"][\"labels\"]).value_counts(), pd.Series(split_ds[\"test\"][\"labels\"]).value_counts(), sep=\"\\n\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    acc = accuracy_score(y_true=labels, y_pred=preds)\n",
    "    return {\"Accuracy\": acc}\n",
    "\n",
    "clf = ImdbBertClassifier(2)\n",
    "\n",
    "for param in clf.parameters():\n",
    "    param.data = param.data.contiguous()\n",
    "    param.requires_grad = False\n",
    "for param in clf.backbone.encoder.layer[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in clf.backbone.pooler.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in clf.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "bs = 16\n",
    "\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=\"checkpoints\",\n",
    "    learning_rate=1e-3,\n",
    "    per_device_train_batch_size=bs,\n",
    "    per_device_eval_batch_size=bs,\n",
    "    num_train_epochs=15,\n",
    "    weight_decay=1e-4,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "trainer = transformers.Trainer(\n",
    "    model=clf,\n",
    "    args=training_args,\n",
    "    train_dataset=split_ds[\"train\"],\n",
    "    eval_dataset=split_ds[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "aacea3b4-db1a-4b99-af1f-81430549c4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd9f03dfaf1a44b8a09bbccf47f22ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26bfacbf6a8045969b7832a7b1759539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b29202fe502b4f47be8ebf98097ca217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stringifying the column:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "972af5b344834e158da3452ab05c3d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d003bdee61644870b22dbaf6fd5fca41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_ds = dataset.from_df(test_df)\n",
    "test_ds.save_to_disk(os.path.join(DATA_DIR, \"test.hf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01b1ee5e-33ba-4aac-a3fd-f45b01d85ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.86004}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds = datasets.load_from_disk(os.path.join(DATA_DIR, \"test.hf\"))\n",
    "compute_metrics(trainer.predict(test_ds)[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a65da36-15ff-431b-b984-760d03de3d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(clf, os.path.join(MODEL_DIR, \"bert_clf2.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e15e24eb-713e-4296-bc50-f06cd3ccf03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(text, path_to_model=os.path.join(MODEL_DIR, \"bert_clf2.pt\")):\n",
    "    model = torch.load(path_to_model, weights_only=False)\n",
    "    model.eval()\n",
    "    model.cpu()\n",
    "    rds = dataset.from_df(pd.DataFrame({\"text\": [text], \"label\": [None], \"rating\": [None]}))\n",
    "    print(rds[\"text\"])\n",
    "    batch = next(iter(rds))\n",
    "    input_ids = torch.tensor(batch[\"input_ids\"]).unsqueeze(0)\n",
    "    attention_mask = torch.tensor(batch[\"attention_mask\"]).unsqueeze(0)\n",
    "    preds = model(input_ids, attention_mask)[0].detach().numpy()\n",
    "    return \"pos\" if np.argmax(preds, axis=1) else \"neg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59a8797d-992a-4942-88bc-bad07c1e8d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e395c9d5a24e81bc1333b3e7fbfba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "114905c019074f8daf082856767a3f3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e549a0bc7c14adabb444dd30441685c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stringifying the column:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a70061860f4ed5af811ad31a27bb51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['boyfriend I go watch Guardian . first I want watch , I love movie- definitely good movie I see sometime . portray uscg well , really show I I think really appreciate . teach really good movie . movie show really hard job . I think uscg would challenge scary . great movie around . I would suggest movie anyone see . ending break heart I know . storyline great I give 2 thumb . I cry emotional , I would give 20 I could !']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11b89fe56bd34b1895866b0922c7f4cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e2fc9a9685649058baed9be8b7b941a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ccd728647246ec92a95b6f3be6bd34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stringifying the column:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7c954d095a434f9b44617a29f89237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"pale imitation ' Officer Gentleman . ' chemistry Kutcher unknown woman play love interest . dialog wooden , situation hackneye . long climax anti - climactic ( ! ) . I love uscg , man woman fearless tough . action scene awesome , movie much recruit , I fear . script formulaic , confusing . Kutcher 's character try redeem accident fault ? Costner 's rage dying light , ? ' conflict ' wife deep mud puddle . I see sneak preview free certainly feel I get money 's worth .\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('pos', 'neg')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_pos = \"\"\"\n",
    "My boyfriend and I went to watch The Guardian.At first I didn't want to watch it, but I loved the movie- It was definitely \n",
    "the best movie I have seen in sometime.They portrayed the USCG very well, it really showed me what they do \n",
    "and I think they should really be appreciated more.Not only did it teach but it was a really good movie. The movie shows \n",
    "what the really do and how hard the job is.I think being a USCG would be challenging and very scary. It was a great movie all around. \n",
    "I would suggest this movie for anyone to see.The ending broke my heart but I know why he did it. The storyline was great \n",
    "I give it 2 thumbs up. I cried it was very emotional, I would give it a 20 if I could!\n",
    "\"\"\"\n",
    "review_neg = \"\"\"\n",
    "This is a pale imitation of 'Officer and a Gentleman.' There is NO chemistry between Kutcher and the unknown woman \n",
    "who plays his love interest. The dialog is wooden, the situations hackneyed. It's too long and the climax is anti-climactic(!). \n",
    "I love the USCG, its men and women are fearless and tough. The action scenes are awesome, but this movie doesn't do much \n",
    "for recruiting, I fear. The script is formulaic, but confusing. Kutcher's character is trying to redeem himself for an accident \n",
    "that wasn't his fault? Costner's is raging against the dying of the light, but why? His 'conflict' with his wife is about as deep \n",
    "as a mud puddle. I saw this sneak preview for free and certainly felt I got my money's worth.\n",
    "\"\"\"\n",
    "predict_label(review_pos), \\\n",
    "predict_label(review_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8fd021-3e24-4a46-9aa0-c78bc38aa380",
   "metadata": {},
   "source": [
    "## Модель для присвоения рейтинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce5a34f4-fd88-4ecd-b34d-6c911654d4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_labels(dataset):\n",
    "    d = {k: dataset[k] for k in dataset.features.keys()}\n",
    "    d[\"labels\"] = dataset[\"rating\"]\n",
    "    d.pop(\"rating\", None)\n",
    "    dataset = Dataset.from_dict(d)\n",
    "    dataset = dataset.class_encode_column(\"labels\")\n",
    "    return dataset\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    acc = accuracy_score(y_true=labels, y_pred=preds)\n",
    "    f1 = f1_score(y_true=labels, y_pred=preds, average=\"macro\")\n",
    "    return {\"Accuracy\": acc, \"F1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25050727-4274-453d-933b-82ec26c5bd22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f570c19c73f45ccbf07f1229f7ae408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stringifying the column:   0%|          | 0/12000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed494235c0f9458f97db8d18e7de32e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/12000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    1200\n",
      "1    1200\n",
      "0    1200\n",
      "5    1200\n",
      "4    1200\n",
      "7    1200\n",
      "6    1200\n",
      "2    1200\n",
      "Name: count, dtype: int64\n",
      "6    300\n",
      "1    300\n",
      "5    300\n",
      "2    300\n",
      "7    300\n",
      "3    300\n",
      "0    300\n",
      "4    300\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9000' max='9000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9000/9000 1:56:22, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.030000</td>\n",
       "      <td>1.869003</td>\n",
       "      <td>0.232500</td>\n",
       "      <td>0.167016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.917700</td>\n",
       "      <td>1.819223</td>\n",
       "      <td>0.245833</td>\n",
       "      <td>0.184070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.889600</td>\n",
       "      <td>1.843386</td>\n",
       "      <td>0.243333</td>\n",
       "      <td>0.168426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.845800</td>\n",
       "      <td>1.812253</td>\n",
       "      <td>0.255417</td>\n",
       "      <td>0.198660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.812600</td>\n",
       "      <td>1.761141</td>\n",
       "      <td>0.273333</td>\n",
       "      <td>0.239726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.796100</td>\n",
       "      <td>1.776707</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.251960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.796100</td>\n",
       "      <td>1.769253</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.263038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.773100</td>\n",
       "      <td>1.735238</td>\n",
       "      <td>0.306250</td>\n",
       "      <td>0.274512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.768200</td>\n",
       "      <td>1.733372</td>\n",
       "      <td>0.299583</td>\n",
       "      <td>0.269951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.750700</td>\n",
       "      <td>1.724300</td>\n",
       "      <td>0.297917</td>\n",
       "      <td>0.264585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.734100</td>\n",
       "      <td>1.742779</td>\n",
       "      <td>0.296667</td>\n",
       "      <td>0.282696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.738100</td>\n",
       "      <td>1.714212</td>\n",
       "      <td>0.307500</td>\n",
       "      <td>0.278198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.721800</td>\n",
       "      <td>1.716544</td>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.264787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.732900</td>\n",
       "      <td>1.710400</td>\n",
       "      <td>0.306250</td>\n",
       "      <td>0.282448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.724200</td>\n",
       "      <td>1.708053</td>\n",
       "      <td>0.302500</td>\n",
       "      <td>0.283429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9000, training_loss=1.7973870849609375, metrics={'train_runtime': 6982.8684, 'train_samples_per_second': 20.622, 'train_steps_per_second': 1.289, 'total_flos': 0.0, 'train_loss': 1.7973870849609375, 'epoch': 15.0})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "train_ds = datasets.load_from_disk(os.path.join(DATA_DIR, \"train.hf\"))\n",
    "train_ds = train_ds.class_encode_column(\"rating\")\n",
    "\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X = np.array(range(train_ds.num_rows))[:,None]\n",
    "y = np.array(train_ds[\"rating\"])\n",
    "X_res, _ = rus.fit_resample(X, y)\n",
    "\n",
    "small_train_ds = train_ds.select(X_res).train_test_split(\n",
    "    train_size=12000, stratify_by_column=\"rating\"\n",
    ")\n",
    "small_train_ds = switch_labels(small_train_ds[\"train\"])\n",
    "split_ds = small_train_ds.train_test_split(\n",
    "    test_size=0.2, stratify_by_column=\"labels\"\n",
    ")\n",
    "print(pd.Series(split_ds[\"train\"][\"labels\"]).value_counts(), pd.Series(split_ds[\"test\"][\"labels\"]).value_counts(), sep=\"\\n\")\n",
    "\n",
    "clf = ImdbBertClassifier(np.unique(y).size)\n",
    "\n",
    "for param in clf.parameters():\n",
    "    param.data = param.data.contiguous()\n",
    "    param.requires_grad = False\n",
    "for param in clf.backbone.encoder.layer[-1].output.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in clf.backbone.pooler.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in clf.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "bs = 16\n",
    "\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=\"checkpoints\",\n",
    "    learning_rate=1e-3,\n",
    "    per_device_train_batch_size=bs,\n",
    "    per_device_eval_batch_size=bs,\n",
    "    num_train_epochs=15,\n",
    "    weight_decay=1e-4,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "trainer = transformers.Trainer(\n",
    "    model=clf,\n",
    "    args=training_args,\n",
    "    train_dataset=split_ds[\"train\"],\n",
    "    eval_dataset=split_ds[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ffe56bd-24b6-4b76-b381-a4ed3227d3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.35936, 'F1': 0.12741014871512976}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds = datasets.load_from_disk(os.path.join(DATA_DIR, \"test.hf\"))\n",
    "compute_metrics(trainer.predict(test_ds)[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6726e06-1e23-485d-a9f0-8319519d6d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(clf, os.path.join(MODEL_DIR, \"bert_clf8.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae5bf35-1462-4745-894e-9d4cd2e48c22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
